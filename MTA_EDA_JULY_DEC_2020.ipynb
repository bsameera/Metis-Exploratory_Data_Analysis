{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///mta_data.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_july = pd.read_sql(\"SELECT * from mta_data WHERE DATE LIKE '07/%/2020';\", engine)\n",
    "df_july.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.read_sql(\"SELECT * from mta_data WHERE DATE LIKE '08/%/2020';\", engine)\n",
    "df_aug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sep = pd.read_sql(\"SELECT * from mta_data WHERE DATE LIKE '09/%/2020';\", engine)\n",
    "df_sep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oct = pd.read_sql(\"SELECT * from mta_data WHERE DATE LIKE '10/%/2020';\", engine)\n",
    "df_oct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nov = pd.read_sql(\"SELECT * from mta_data WHERE DATE LIKE '11/%/2020';\", engine)\n",
    "df_nov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dec = pd.read_sql(\"SELECT * from mta_data WHERE DATE LIKE '12/%/2020';\", engine)\n",
    "df_dec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_july, df_aug, df_sep, df_oct, df_nov, df_dec], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.strip() for col in df.columns]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and delete rows with null values if any\n",
    "df.loc[df.isna().sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with values zero\n",
    "df.loc[df['ENTRIES']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['ENTRIES']==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if rows with zero value are deleted from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ENTRIES']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date and time datatypes are string, let's convert date to datetime and form a new column by combining date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df[\"DATE_TIME\"] = pd.to_datetime(df.DATE + \" \" + df.TIME, \n",
    "                                            format=\"%m/%d/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime type\n",
    "df[\"DATE\"] = pd.to_datetime(df.DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicate rows\n",
    "df.sort_values([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True, ascending=False)\n",
    "df.drop_duplicates(subset=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if duplicate values have been deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the column DESC and the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DESC.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"DESC\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each combination of C/A, UNIT, SCP, and STATION represents a unique turnstile. Let's take a look at one specific turnstile on a specific date. What does each row in the dataframe represent? Obtain the maximum ENTRIES value for each day, for each unique turnstile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"C/A\"] == \"A002\") & \n",
    "(df[\"UNIT\"] == \"R051\") & \n",
    "(df[\"SCP\"] == \"02-00-00\") & \n",
    "(df[\"STATION\"] == \"59 ST\") &\n",
    "(df[\"DATE\"] == \"05/25/2020\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE\"],as_index=False).ENTRIES.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the daily entries i.e the number of people traveling on each day. Group the data by turnstile and use the Pandas .apply() method to compute the same differencing function for each turnstile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (df_daily.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"].apply(lambda grp: grp.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.dropna(subset=[\"PREV_DATE\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Entries\n",
    "Let's look at some more weirdness in the data and think about handling it before we finalize our daily count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily[\"ENTRIES\"] < df_daily[\"PREV_ENTRIES\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for one particular turnstyle, the reverse counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((df[\"C/A\"] == \"A011\") & \n",
    "(df[\"UNIT\"] == \"R080\") & \n",
    "(df[\"SCP\"] == \"01-00-00\") & \n",
    "(df[\"STATION\"] == \"57 ST-7 AV\") &\n",
    "(df[\"DATE_TIME\"].dt.date == datetime.datetime(2020, 8, 27).date()))\n",
    "\n",
    "df[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many stations have this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_daily[df_daily[\"ENTRIES\"] < df_daily[\"PREV_ENTRIES\"]]\n",
    "    .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "    .size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_counts(row, max_counter):\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "# It'd probably be a good idea to use a number even significantly smaller than 1 million as the limit!\n",
    "df_daily[\"DAILY_ENTRIES\"] = df_daily.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been operating on a single turnstile level. Now let's combine turnstiles that fall within the same ControlArea/Unit/Station combo. There are some ControlArea/Unit/Station groups that have a single turnstile, but most have multiple turnstiles -- same value for the C/A, UNIT and STATION columns, different values for the SCP column.\n",
    "\n",
    "We want to combine the numbers together. For each ControlArea/UNIT/STATION combo, for each day, sum the counts from each turnstile belonging to that combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_unit_station_daily = df_daily.groupby([\"C/A\", \"UNIT\", \"STATION\", \"DATE\"])[['DAILY_ENTRIES']].sum().reset_index()\n",
    "ca_unit_station_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_unit_station_daily_sum = ca_unit_station_daily.groupby(\"DATE\")[\"DAILY_ENTRIES\"].mean().reset_index()\n",
    "ca_unit_station_daily_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the daily traffic for the months of May, June, July, August, for the year 2020. We can see the daily traffic is increasing slowly as compared to the beginning of May, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(ca_unit_station_daily_sum.DATE, ca_unit_station_daily_sum.DAILY_ENTRIES, color='red', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the holiday seasons are busiest days from the six month period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily entries for the month of July 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_july_2020_daily = ca_unit_station_daily.loc[(ca_unit_station_daily['DATE'].dt.month == 7) & (ca_unit_station_daily[\"DATE\"].dt.year==2020)][[\"STATION\", \"DATE\", \"DAILY_ENTRIES\"]]\n",
    "df_july_2020_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily_july_2020 = df_july_2020_daily.groupby([\"STATION\"])[['DAILY_ENTRIES']].sum().reset_index().sort_values('DAILY_ENTRIES', ascending=False)\n",
    "station_daily_july_2020\n",
    "# manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(station_daily_july_2020.STATION.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily entries for the month of August 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_2020_daily = ca_unit_station_daily.loc[(ca_unit_station_daily['DATE'].dt.month == 8) & (ca_unit_station_daily[\"DATE\"].dt.year==2020)][[\"STATION\", \"DATE\", \"DAILY_ENTRIES\"]]\n",
    "df_aug_2020_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily_aug_2020 = df_aug_2020_daily.groupby([\"STATION\"])[['DAILY_ENTRIES']].sum().reset_index().sort_values('DAILY_ENTRIES', ascending=False)\n",
    "station_daily_aug_2020\n",
    "# manhattan financial district"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily entries for the month of September 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sep_2020_daily = ca_unit_station_daily.loc[(ca_unit_station_daily['DATE'].dt.month == 9) & (ca_unit_station_daily[\"DATE\"].dt.year==2020)][[\"STATION\", \"DATE\", \"DAILY_ENTRIES\"]]\n",
    "df_sep_2020_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily_sep_2020 = df_sep_2020_daily.groupby([\"STATION\"])[['DAILY_ENTRIES']].sum().reset_index().sort_values('DAILY_ENTRIES', ascending=False)\n",
    "station_daily_sep_2020\n",
    "\n",
    "# Queens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['34 ST-PENN STA', 'FULTON ST', '34 ST-HERALD SQ', 'GRD CNTRL-42 ST', 'FLUSHING-MAIN', '23 ST', '86 ST', '125 ST']\n",
    "y = []\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.barh(x, y, color=['grey', 'lightblue', 'pink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily entries for the month of October 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oct_2020_daily = ca_unit_station_daily.loc[(ca_unit_station_daily['DATE'].dt.month == 10) & (ca_unit_station_daily[\"DATE\"].dt.year==2020)][[\"STATION\", \"DATE\", \"DAILY_ENTRIES\"]]\n",
    "df_oct_2020_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily_oct_2020 = df_oct_2020_daily.groupby([\"STATION\"])[['DAILY_ENTRIES']].sum().reset_index().sort_values('DAILY_ENTRIES', ascending=False)\n",
    "station_daily_oct_2020\n",
    "# manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily entries for the month of November 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nov_2020_daily = ca_unit_station_daily.loc[(ca_unit_station_daily['DATE'].dt.month == 11) & (ca_unit_station_daily[\"DATE\"].dt.year==2020)][[\"STATION\", \"DATE\", \"DAILY_ENTRIES\"]]\n",
    "df_nov_2020_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily_nov_2020 = df_nov_2020_daily.groupby([\"STATION\"])[['DAILY_ENTRIES']].sum().reset_index().sort_values('DAILY_ENTRIES', ascending=False)\n",
    "station_daily_nov_2020\n",
    "# manhattan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily entries for the month of December 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dec_2020_daily = ca_unit_station_daily.loc[(ca_unit_station_daily['DATE'].dt.month == 12) & (ca_unit_station_daily[\"DATE\"].dt.year==2020)][[\"STATION\", \"DATE\", \"DAILY_ENTRIES\"]]\n",
    "df_dec_2020_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily_dec_2020 = df_dec_2020_daily.groupby([\"STATION\"])[['DAILY_ENTRIES']].sum().reset_index().sort_values('DAILY_ENTRIES', ascending=False)\n",
    "station_daily_dec_2020\n",
    "# manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the daily time series for each STATION for all the months, by adding up all the turnstiles in a station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_daily = df_daily.groupby([\"STATION\", \"DATE\"])[['DAILY_ENTRIES']].sum().reset_index()\n",
    "station_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum total ridership for each station and sort them, so you can find out the stations with the highest traffic during the time you investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_totals = station_daily.groupby('STATION').sum()\\\n",
    "    .sort_values('DAILY_ENTRIES', ascending=False)\\\n",
    "    .reset_index()\n",
    "\n",
    "station_totals.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['34 ST-PENN STA', 'FULTON ST', '34 ST-HERALD SQ', 'GRD CNTRL-42 ST', 'FLUSHING-MAIN', '23 ST', '86 ST', '125 ST']\n",
    "y = [7473555.0, 5664641.0, 4923146.0, 4710694.0, 4493024.0, 4412771.0, 4155236.0, 3863366.0]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.barh(x, y, color=['grey', 'lightblue', 'pink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the top 20 stations with the highest traffic. The top 8 stations traffic over the six months, post covid lockdown is shown in the bar plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
